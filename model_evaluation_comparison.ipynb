{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares the performance of:\n",
    "1. **Logistic Regression** (Baseline)\n",
    "2. **Custom Neural Network** (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data (same as in neural_network.ipynb)\n",
    "data = pd.read_csv(\"wdbc.data\", header=None)\n",
    "\n",
    "# Add column names\n",
    "data.columns = [\"id\", \"diagnosis\", \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \n",
    "                \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \n",
    "                \"symmetry1\", \"fractal_dimension1\", \"radius2\", \"texture2\", \n",
    "                \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \n",
    "                \"concavity2\", \"concave_points2\", \"symmetry2\", \n",
    "                \"fractal_dimension2\", \"radius3\", \"texture3\", \"perimeter3\", \n",
    "                \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \n",
    "                \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"]\n",
    "\n",
    "# Prepare features and target\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "y = (data['diagnosis'] == 'M').astype(int)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Neural Network Class\n",
    "\n",
    "Copied the SimpleNeuralNetwork class from neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def relu_derivative(self, Z):\n",
    "        return (Z > 0).astype(float)\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-np.clip(Z, -500, 500)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.A1 = self.relu(self.Z1)\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.sigmoid(self.Z2)\n",
    "        return self.A2\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        dZ2 = self.A2 - y.reshape(-1, 1)\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * self.relu_derivative(self.Z1)\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = len(y_true)\n",
    "        y_true = y_true.reshape(-1, 1)\n",
    "        loss = -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.1):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            losses.append(loss)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "print(\"✓ Neural Network class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Logistic Regression...\")\n",
    "logreg = LogisticRegression(max_iter=10000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "y_pred_proba_logreg = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\" Logistic Regression - Test Accuracy: {accuracy_score(y_test, y_pred_logreg):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Neural Network...\")\n",
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "\n",
    "nn = SimpleNeuralNetwork(input_size, hidden_size, output_size)\n",
    "losses = nn.train(X_train_scaled, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "y_pred_nn = nn.predict(X_test_scaled).flatten()\n",
    "y_pred_proba_nn = nn.predict_proba(X_test_scaled).flatten()\n",
    "\n",
    "print(f\"\\n✓ Neural Network - Test Accuracy: {accuracy_score(y_test, y_pred_nn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate All Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': auc(fpr, tpr),\n",
    "        'Avg Precision': average_precision_score(y_true, y_pred_proba)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "metrics_logreg = calculate_metrics(y_test, y_pred_logreg, y_pred_proba_logreg, 'Logistic Regression')\n",
    "metrics_nn = calculate_metrics(y_test, y_pred_nn, y_pred_proba_nn, 'Neural Network')\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_logreg, metrics_nn]).set_index('Model')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(metrics_df.round(4))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Metric Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metrics_df.T.plot(kind='bar', ax=ax, color=['#3498db', '#e74c3c'], width=0.8)\n",
    "plt.title('Model Performance Comparison', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Score', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Model', frameon=True, shadow=True)\n",
    "plt.ylim([0.85, 1.0])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Best Performance by Metric:\")\n",
    "print(\"-\" * 40)\n",
    "for col in metrics_df.columns:\n",
    "    best_model = metrics_df[col].idxmax()\n",
    "    best_score = metrics_df[col].max()\n",
    "    print(f\"{col:15s}: {best_model:20s} ({best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Benign', 'Malignant'],\n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "axes[0].set_title('Logistic Regression', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Neural Network\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
    "            xticklabels=['Benign', 'Malignant'],\n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "axes[1].set_title('Neural Network', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed analysis\n",
    "for name, cm in [('Logistic Regression', cm_logreg), ('Neural Network', cm_nn)]:\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fn_rate = fn / (fn + tp) * 100\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  True Negatives:  {tn}  |  False Positives: {fp}\")\n",
    "    print(f\"  False Negatives: {fn}  |  True Positives:  {tp}\")\n",
    "    print(f\"    False Negative Rate: {fn_rate:.2f}% (missed cancer cases)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ROC Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_pred_proba_logreg)\n",
    "roc_auc_logreg = auc(fpr_logreg, tpr_logreg)\n",
    "\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_pred_proba_nn)\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_logreg, tpr_logreg, color='#3498db', lw=2.5, \n",
    "         label=f'Logistic Regression (AUC = {roc_auc_logreg:.4f})')\n",
    "plt.plot(fpr_nn, tpr_nn, color='#e74c3c', lw=2.5, \n",
    "         label=f'Neural Network (AUC = {roc_auc_nn:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=16, fontweight='bold', pad=15)\n",
    "plt.legend(loc='lower right', fontsize=11, frameon=True, shadow=True)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - Classification Report\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred_logreg, \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEURAL NETWORK - Classification Report\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred_nn, \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loss Visualization (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses, color='#e74c3c', linewidth=2)\n",
    "plt.title('Neural Network Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Loss: {losses[0]:.4f}\")\n",
    "print(f\"Final Loss: {losses[-1]:.4f}\")\n",
    "print(f\"Loss Reduction: {(1 - losses[-1]/losses[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY & CONCLUSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_f1_model = metrics_df['F1-Score'].idxmax()\n",
    "best_f1_score = metrics_df['F1-Score'].max()\n",
    "best_recall_model = metrics_df['Recall'].idxmax()\n",
    "best_recall_score = metrics_df['Recall'].max()\n",
    "\n",
    "print(f\"\\n Best Overall Model (F1-Score): {best_f1_model}\")\n",
    "print(f\"   F1-Score: {best_f1_score:.4f}\")\n",
    "print(f\"\\n Best at Detecting Cancer (Recall): {best_recall_model}\")\n",
    "print(f\"   Recall: {best_recall_score:.4f}\")\n",
    "\n",
    "acc_diff = abs(metrics_df.loc['Neural Network', 'Accuracy'] - \n",
    "               metrics_df.loc['Logistic Regression', 'Accuracy'])\n",
    "\n",
    "print(\"\\n Key Findings:\")\n",
    "print(\"-\" * 70)\n",
    "if acc_diff < 0.02:\n",
    "    print(\"• Models perform very similarly (< 2% difference)\")\n",
    "    print(\"• Both models are effective for this classification task\")\n",
    "elif metrics_df.loc['Neural Network', 'Accuracy'] > metrics_df.loc['Logistic Regression', 'Accuracy']:\n",
    "    print(f\"• Neural Network outperforms by {acc_diff*100:.2f}% in accuracy\")\n",
    "    print(\"• Neural Network captures additional non-linear patterns\")\n",
    "else:\n",
    "    print(f\"• Logistic Regression outperforms by {acc_diff*100:.2f}%\")\n",
    "    print(\"• Data relationships are primarily linear\")\n",
    "\n",
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "fn_rate_logreg = cm_logreg[1, 0] / (cm_logreg[1, 0] + cm_logreg[1, 1]) * 100\n",
    "fn_rate_nn = cm_nn[1, 0] / (cm_nn[1, 0] + cm_nn[1, 1]) * 100\n",
    "\n",
    "print(f\"\\n Clinical Considerations:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"• RECALL is critical - missing cancer is worse than false alarms\")\n",
    "print(f\"\\n  False Negative Rates:\")\n",
    "print(f\"  • Logistic Regression: {fn_rate_logreg:.2f}%\")\n",
    "print(f\"  • Neural Network: {fn_rate_nn:.2f}%\")\n",
    "\n",
    "print(\"\\n Recommendations:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"1. Both models achieve excellent performance (>95% accuracy)\")\n",
    "print(\"2. Consider ensemble methods for even better results\")\n",
    "print(\"3. Adjust decision threshold to minimize false negatives\")\n",
    "print(\"4. Next step: Implement image-based YOLO model on CBIS-DDSM dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Analysis Complete - Results Ready\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics comparison\n",
    "metrics_df.to_csv('model_comparison_results.csv')\n",
    "print(\"✓ Saved: model_comparison_results.csv\")\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'metrics': metrics_df,\n",
    "    'best_f1_model': best_f1_model,\n",
    "    'best_recall_model': best_recall_model,\n",
    "    'confusion_matrices': {\n",
    "        'logistic_regression': cm_logreg,\n",
    "        'neural_network': cm_nn\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('evaluation_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "print(\"✓ Saved: evaluation_summary.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
